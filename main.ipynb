{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LiVqDaXQKZfW",
    "outputId": "d841a384-31d0-47e6-91ca-29abb32fe6ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 50\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "import PIL\n",
    "from PIL import Image, ImageFilter\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# seed everything\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "class PrintedDigitsDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, random_dilation=False, meta='font_list.txt'):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.random_dilation = random_dilation\n",
    "        self.samples = []\n",
    "        with open(os.path.join(root_dir, meta)) as f:\n",
    "            font_list = f.read().splitlines()\n",
    "\n",
    "        for font_folder in font_list:\n",
    "            font_path = os.path.join(root_dir, font_folder)\n",
    "            for label in range(10):\n",
    "                image_path = os.path.join(font_path, f'{label}/{label}.png')\n",
    "                self.samples.append((image_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, label = self.samples[idx]\n",
    "        image = PIL.ImageOps.invert(Image.open(image_path).convert(\"RGB\"))\n",
    "        if self.random_dilation:\n",
    "            dilation_width = random.randrange(1, 11, 2)\n",
    "            image = image.resize((128, 128)).filter(ImageFilter.MaxFilter(dilation_width))\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "data_path = \"./printed_digits\"\n",
    "train_dataset = PrintedDigitsDataset(root_dir=data_path, transform=transform, random_dilation=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "print(f\"Total samples: {len(train_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rTIQiQO5NEx6"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DigitClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(DigitClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        self.fc1 = nn.Linear(4096, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kBiND-uyNPsn",
    "outputId": "24bbd01a-fd6e-47e8-c216-f6510d778aa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/70, Loss: 0.4332, Accuracy: 98.00%%\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = DigitClassifier(num_classes=10).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "def train_model(model, train_loader, optimizer, criterion, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        print('\\r', end='')\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss:.4f}, Accuracy: {accuracy:.2f}%\", end='')\n",
    "    print()\n",
    "train_model(model, train_loader, optimizer, criterion, epochs=70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KoHGT9kfNhws",
    "outputId": "954fb610-cf2e-4967-af86-3fb24faf99db"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"digit_classifier_printed.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "V0_sSM8wNl3D"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.00%\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "test_dataset = PrintedDigitsDataset(root_dir=data_path, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 99
    },
    "id": "gbKjRo98NrGU",
    "outputId": "52980317-97fe-4160-dd74-3b27976613b1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "mnist_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img : img.convert('RGB')),\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "mnist_test_dataset = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=mnist_transform\n",
    ")\n",
    "\n",
    "# mnist_test_dataset = torch.utils.data.Subset(mnist_test_dataset, list(range(128)))\n",
    "\n",
    "mnist_test_loader = DataLoader(mnist_test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "# def show_mnist_images(data_loader):\n",
    "#     data_iter = iter(data_loader)\n",
    "#     images, labels = next(data_iter)\n",
    "#     images = images.squeeze(1)\n",
    "\n",
    "#     fig, axes = plt.subplots(1, len(images), figsize=(15, 5))\n",
    "#     for idx, (img, label) in enumerate(zip(images, labels)):\n",
    "#         axes[idx].imshow(img.numpy().transpose(1, 2, 0) * 0.5 + 0.5)\n",
    "#         axes[idx].set_title(f\"Label: {label.item()}\")\n",
    "#         axes[idx].axis(\"off\")\n",
    "#     plt.show()\n",
    "\n",
    "# show_mnist_images(mnist_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ClrBFHYNOjx7",
    "outputId": "fa7a3426-4066-42e6-d6fa-8b84463014bd",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 37.34%\n"
     ]
    }
   ],
   "source": [
    "model = DigitClassifier(num_classes=10).to(device)\n",
    "model.load_state_dict(torch.load(\"digit_classifier_printed.pth\", weights_only=True))\n",
    "test_model(model, mnist_test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Loss: 4.8183, Accuracy: 99.37%\n",
      "Test Accuracy: 98.90%\n"
     ]
    }
   ],
   "source": [
    "mnist_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img : img.convert('RGB')),\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "mnist_train_dataset = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=mnist_transform\n",
    ")\n",
    "\n",
    "mnist_train_loader = DataLoader(mnist_train_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "model = DigitClassifier(num_classes=10).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "train_model(model, mnist_train_loader, optimizer, criterion, epochs=10)\n",
    "test_model(model, mnist_test_loader)\n",
    "torch.save(model.state_dict(), \"digit_classifier_mnist.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from diffusers import UNet2DModel\n",
    "from pipeline_ddpm_custom import DDPMPipelineCustom\n",
    "from scheduling_rectflow import RectFlowScheduler, RectFlowInverseScheduler\n",
    "\n",
    "def get_beautifier(model_dir, classifier, device='cpu', num_inverse_step=200, num_denoise_step=50, printed_digits_dir=\"./printed_digits\"):\n",
    "    printed_digits = {}\n",
    "    total_fonts = 0\n",
    "    total_images = 0\n",
    "    for font in os.listdir(printed_digits_dir):\n",
    "        font_path = os.path.join(printed_digits_dir, font)\n",
    "        if os.path.isdir(font_path):\n",
    "            total_fonts += 1  # Count fonts\n",
    "            for digit in range(10):\n",
    "                digit_folder = os.path.join(font_path, str(digit))\n",
    "                if os.path.exists(digit_folder):\n",
    "                    images = [\n",
    "                        transforms.functional.to_tensor(\n",
    "                            PIL.ImageOps.invert(Image.open(os.path.join(digit_folder, img_path)).resize((32, 32)).convert(\"RGB\"))\n",
    "                        ) * 2 - 1\n",
    "                        for img_path in os.listdir(digit_folder)\n",
    "                        if img_path.endswith(\".png\")\n",
    "                    ]\n",
    "                    total_images += len(images)\n",
    "                    printed_digits.setdefault(digit, []).extend(images)\n",
    "    \n",
    "\n",
    "    unet = UNet2DModel.from_pretrained(f\"{model_dir}/unet\")\n",
    "    scheduler_config_path = os.path.join(model_dir, \"scheduler\", \"scheduler_config.json\")\n",
    "    scheduler = RectFlowScheduler.from_config(scheduler_config_path)\n",
    "    scheduler_inv = RectFlowInverseScheduler.from_config(scheduler_config_path)\n",
    "    unet.to(device)\n",
    "    classifier.to(device)\n",
    "    \n",
    "    pipeline = DDPMPipelineCustom(\n",
    "        unet=unet,\n",
    "        scheduler=scheduler,\n",
    "    )\n",
    "    pipeline_inv = DDPMPipelineCustom(\n",
    "        unet=unet,\n",
    "        scheduler=scheduler_inv,\n",
    "    )\n",
    "    pipeline.set_progress_bar_config(disable=True)\n",
    "    pipeline_inv.set_progress_bar_config(disable=True)\n",
    "    class_conditioning = unet.class_embedding is not None\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def beautifier(images, alpha):\n",
    "        classifier.eval()\n",
    "        _, labels = torch.max(classifier(images), 1)\n",
    "        printed = torch.stack([\n",
    "            random.choice(printed_digits[label.item()])\n",
    "            for (image, label) in zip(images, labels)\n",
    "        ]).to(images.device)\n",
    "        \n",
    "        # Run noise inversion\n",
    "        images = torch.cat([images, printed])\n",
    "        labels = torch.cat([labels] * 2) if class_conditioning else None\n",
    "        semantic_noise = pipeline_inv(labels, init_noise=images, clamp_output=False, num_inference_steps=num_inverse_step, output_type='pt').images\n",
    "        z_images, z_printed = semantic_noise.chunk(2)\n",
    "\n",
    "        # interpolation\n",
    "        interp_z = alpha * z_printed + (1 - alpha) * z_images\n",
    "        \n",
    "        # denoise from interpolated semantic noise\n",
    "        labels = labels.chunk(2)[0] if class_conditioning else None\n",
    "        interp = pipeline(labels, init_noise=interp_z * 2 - 1, num_inference_steps=num_denoise_step, output_type='pt').images\n",
    "        return interp\n",
    "    \n",
    "    return beautifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_handwriting_beautification(model, test_loader, beautifier, alpha):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in tqdm(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        images = beautifier(images, alpha) * 2 - 1\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cls_cnd_aug_printed with alpha 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/schu23/mldl/project/Handwriting-Beautification/diffusers/src/diffusers/configuration_utils.py:245: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a scheduler, please use <class 'scheduling_rectflow.RectFlowScheduler'>.from_pretrained(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.\n",
      "  deprecate(\"config-passed-as-path\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
      "/data/schu23/mldl/project/Handwriting-Beautification/diffusers/src/diffusers/configuration_utils.py:245: FutureWarning: It is deprecated to pass a pretrained model name or path to `from_config`.If you were trying to load a scheduler, please use <class 'scheduling_rectflow.RectFlowInverseScheduler'>.from_pretrained(...) instead. Otherwise, please make sure to pass a configuration dictionary instead. This functionality will be removed in v1.0.0.\n",
      "  deprecate(\"config-passed-as-path\", \"1.0.0\", deprecation_message, standard_warn=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16abb26fc03e4dd09636aeaacb77e41c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 45.72%\n",
      "Running cls_cnd_aug_printed with alpha 0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e90ba0a18c423dbccc7c91869ae921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 63.46%\n",
      "Running cls_cnd_aug_printed with alpha 0.15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8334b743ea8f4d0f80d59be651a897a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 76.12%\n",
      "Running cls_cnd_aug_printed with alpha 0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a92770f2b2d44a2cb8a364de2d36b21c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 84.84%\n",
      "Running uncnd_aug_printed with alpha 0.05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1f5c746f7c406780c95b688d213ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 35.90%\n",
      "Running uncnd_aug_printed with alpha 0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccfa0b0a7666407d974f1ae064656dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 44.09%\n",
      "Running uncnd_aug_printed with alpha 0.15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ded238c2fda462a842ebbb71801d4c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 53.61%\n",
      "Running uncnd_aug_printed with alpha 0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de2ffb491d64a06ac062ed89dd66c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 64.25%\n"
     ]
    }
   ],
   "source": [
    "classifier = DigitClassifier(num_classes=10).to(device)\n",
    "classifier.load_state_dict(torch.load(\"digit_classifier_mnist.pth\", weights_only=True))\n",
    "model = DigitClassifier(num_classes=10).to(device)\n",
    "model.load_state_dict(torch.load(\"digit_classifier_printed.pth\", weights_only=True))\n",
    "\n",
    "for config in ['cls_cnd_aug_printed', 'uncnd_aug_printed']:\n",
    "    for alpha in [0.05, 0.1, 0.15, 0.2]:\n",
    "        print(f'Running {config} with alpha {alpha}')\n",
    "        beautifier = get_beautifier(f'./output/{config}/', classifier, device)\n",
    "        acc = evaluate_handwriting_beautification(model, mnist_test_loader, beautifier, alpha)\n",
    "        with open(f'nb_logs/{alpha}_{config}.txt', 'w') as f:\n",
    "            f.write(str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
